"""
[summary]
"""
import os
import pickle
import shutil
from typing import Dict, List, Any

import semver
import attr
import yaml
from simpletransformers.classification import ClassificationModel  #type: ignore
from simpletransformers.ner import NERModel

from [[python_package_import_name]] import constants as const
from [[python_package_import_name]].dev.prepare import prepare
from [[python_package_import_name]].dev.io.reader.csv import (
    read_multilabel_dataset_csv,
    save_classification_report,
    save_ner_report,
)

[% raw %]
@attr.s
class Config: ðŸ¥ž
    """
    An instance of config handles `config/config.yaml` configurations. This includes reading other related files, models, datasets, etc.
    
    An instance can:

    - Read config.yaml
    - Modify config.yaml
    - Load models and their configurations
    - Save pickled objects.
    """
    # **config_path**
    #
    # In case config/config.yaml is not the appropriate location.
    config_path = attr.ib(default=os.path.join("config", "config.yaml"))

    # **project_name**
    #
    # The name of your project.
    project_name = attr.ib(default=None)

    # **_config**
    #
    # Read contents of `config.yaml` into a Dict.
    _config = attr.ib(default=None)

    # **version**
    #
    # Current project version.
    version = attr.ib(default=None)

    # **n_cores**
    #
    # Number of cpu cores to use for certain jobs.
    n_cores = attr.ib(default=None)

    # **classification_threshold**
    #
    # Confidence threshold for classification tasks.
    classification_threshold = attr.ib(default=None)

    # **ner_threshold**
    #
    # Confidence threshold for NER tasks.
    ner_threshold = attr.ib(default=None)

    # **rules**
    #
    # Rules for filling Entities within Intent slots.
    rules = attr.ib(default=None)

    def __attrs_post_init__(self) -> None:
        """
        Update default values of attributes from `conifg.yaml`.
        """
        with open(self.config_path, "r") as handle:
            self._config = yaml.load(handle, Loader=yaml.FullLoader)
        semver.VersionInfo.parse(self._config.get(const.VERSION))
        self.version = self._config.get(const.VERSION)
        self.n_cores = self._config.get(const.CORES)
        self.classification_threshold = self._config[const.TASKS][const.CLASSIFICATION][
            const.THRESHOLD
        ]
        self.ner_threshold = self._config[const.TASKS][const.NER][const.THRESHOLD]
        self.rules = self._config[const.RULES]

    def set_version(self, version) -> "Config":
        self.version = version
        self._config[const.VERSION] = version
        return self

    def get_data_dir(self, task) -> str:
        return os.path.join(const.DATA, self.version, task)

    def get_metrics_dir(self, task) -> str:
        return os.path.join(self.get_data_dir(task), const.METRICS)

    def get_model_dir(self, task) -> str:
        return os.path.join(self.get_data_dir(task), const.MODELS)

    def get_model_path(self, task) -> str:
        return os.path.join(self.get_model_dir(task), self.version)

    def get_dataset(self, task, purpose) -> Any:
        data_dir = os.path.join(const.DATA, self.version, task)
        dataset_dir = os.path.join(data_dir, const.DATASETS)
        dataset_file = os.path.join(dataset_dir, f"{purpose}.csv")
        alias = self.get_alias(task)

        if task == const.CLASSIFICATION:
            return prepare(dataset_file, alias, n_cores=self.n_cores)
        elif task == const.NER:
            return read_multilabel_dataset_csv(dataset_file)
        raise ValueError(f"Expected task to be {const.CLASSIFICATION} or {const.NER} instead, {task} was found")

    def get_model_args(self, task, purpose) -> Dict[str, Any]:
        model_args = self._config[const.TASKS][task][const.S_MODEL_ARGS][purpose]
        model_args[const.S_OUTPUT_DIR] = self.get_model_dir(task)
        model_args[const.S_BEST_MODEL] = self.get_model_dir(task)
        n_epochs = model_args.get(const.S_NUM_TRAIN_EPOCHS)
        eval_batch_size = model_args.get(const.S_EVAL_BATCH_SIZE)

        if purpose == const.TRAIN:
            model_args[const.S_EVAL_DURING_TRAINING_STEPS] = (
                n_epochs * eval_batch_size + const.k
            )

        return model_args

    def get_classification_model(self, purpose, tags) -> ClassificationModel:
        model_args = self.get_model_args(const.CLASSIFICATION, purpose)
        return ClassificationModel(
            const.S_XLMR,
            (
                const.S_XLMRB
                if purpose == const.TRAIN
                else model_args[const.S_BEST_MODEL]
            ),
            num_labels=len(tags),
            use_cuda=(purpose != const.PROD),
            args=model_args,
        )

    def get_ner_model(self, purpose, tags) -> NERModel:
        model_args = self.get_model_args(const.NER, purpose)
        return NERModel(
            const.S_XLMR,
            (
                const.S_XLMRB
                if purpose == const.TRAIN
                else model_args[const.S_OUTPUT_DIR]
            ),
            labels=tags,
            use_cuda=(purpose != const.PROD),
            args=model_args,
        )

    def get_labels(self, task) -> List[str]:
        return self._config.get(const.TASKS, {}).get(task, {}).get(const.LABELS)

    def get_alias(self, task) -> List[str]:
        return self._config.get(const.TASKS, {}).get(task, {}).get(const.ALIAS)

    def get_model(self, task, purpose):
        tags = self.get_labels(task)

        if task == const.CLASSIFICATION:
            return self.get_classification_model(purpose, tags)
        elif task == const.NER:
            return self.get_ner_model(purpose, tags)
        raise ValueError(f"Expected task to be {const.CLASSIFICATION} or {const.NER} instead, {task} was found")

    def save_pickle(self, task, prop, value) -> "Config":
        model_dir = self.get_model_dir(task)
        with open(os.path.join(model_dir, prop), "wb") as handle:
            pickle.dump(value, handle)
        return self

    def load_pickle(self, task, prop):
        model_dir = self.get_model_dir(task)
        with open(os.path.join(model_dir, prop), "rb") as handle:
            return pickle.load(handle)

    def save(self) -> "Config":
        with open(self.config_path, "w") as handle:
            yaml.dump(self._config, handle, sort_keys=False)
        return self

    def save_report(self, task, results) -> "Config":
        if task == const.CLASSIFICATION:
            save_classification_report(results[0], results[1], self.get_metrics_dir(task))
            return self
        elif task == const.NER:
            save_ner_report(results, self.get_metrics_dir(task))
            return self
        raise ValueError(f"Expected task to be {const.CLASSIFICATION} or {const.NER} instead, {task} was found")

    def remove_checkpoints(self, task) -> None:
        model_dir = self.get_model_dir(task)
        items = os.listdir(model_dir)
        for item in items:
            subdir = os.path.join(model_dir, item)
            if os.path.isdir(subdir):
                shutil.rmtree(subdir)
[% endraw %]